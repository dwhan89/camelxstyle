{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da00d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code borrowed from https://github.com/rosinality/stylegan2-pytorch\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "from torch import autograd, optim, nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "from torchvision import utils, transforms\n",
    "\n",
    "import camelxstyle.swagan as swagan\n",
    "from camelxstyle.distributed import get_rank, reduce_sum, get_world_size, reduce_loss_dict, synchronize\n",
    "from camelxstyle.nonleaky import augment, AdaptiveAugment\n",
    "from camelxstyle.op import conv2d_gradfix\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except ImportError:\n",
    "    wandb = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9752eb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdwhan89\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dwhan89/camelxstyle/runs/1oviq1lm\" target=\"_blank\">resilient-capybara-5</a></strong> to <a href=\"https://wandb.ai/dwhan89/camelxstyle\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dwhan89/camelxstyle/runs/1oviq1lm?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f24c243a1d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"camelxstyle\", entity=\"dwhan89\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56651191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ng_reg_ratio = args.g_reg_every / (args.g_reg_every + 1)\\nd_reg_ratio = args.d_reg_every / (args.d_reg_every + 1)\\n\\ng_optim = optim.Adam(\\n    generator.parameters(),\\n    lr=args.lr * g_reg_ratio,\\n    betas=(0 ** g_reg_ratio, 0.99 ** g_reg_ratio),\\n)\\nd_optim = optim.Adam(\\n    discriminator.parameters(),\\n    lr=args.lr * d_reg_ratio,\\n    betas=(0 ** d_reg_ratio, 0.99 ** d_reg_ratio),\\n)\\n\\nif args.ckpt is not None:\\n    print(\"load model:\", args.ckpt)\\n\\n    ckpt = torch.load(args.ckpt, map_location=lambda storage, loc: storage)\\n\\n    try:\\n        ckpt_name = os.path.basename(args.ckpt)\\n        args.start_iter = int(os.path.splitext(ckpt_name)[0])\\n\\n    except ValueError:\\n        pass\\n\\n    generator.load_state_dict(ckpt[\"g\"])\\n    discriminator.load_state_dict(ckpt[\"d\"])\\n    g_ema.load_state_dict(ckpt[\"g_ema\"])\\n\\n    g_optim.load_state_dict(ckpt[\"g_optim\"])\\n    d_optim.load_state_dict(ckpt[\"d_optim\"])\\n\\n    if args.distributed:\\n        generator = nn.parallel.DistributedDataParallel(\\n            generator,\\n            device_ids=[args.local_rank],\\n            output_device=args.local_rank,\\n            broadcast_buffers=False,\\n        )\\n\\n        discriminator = nn.parallel.DistributedDataParallel(\\n            discriminator,\\n            device_ids=[args.local_rank],\\n            output_device=args.local_rank,\\n            broadcast_buffers=False,\\n        )\\n\\ntransform = transforms.Compose(\\n    [\\n        transforms.RandomHorizontalFlip(),\\n        transforms.ToTensor(),\\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\\n    ]\\n)\\n\\ndataset = None\\nloader = data.DataLoader(\\n    dataset,\\n    batch_size=args.batch,\\n    sampler=data_sampler(dataset, shuffle=True, distributed=False),\\n    drop_last=True,\\n)\\n\\nif get_rank() == 0 and wandb is not None and args.wandb:\\n    wandb.init(project=\"camelxstyle\")\\n\\n#train(args, loader, generator, discriminator, g_optim, d_optim, g_ema, device)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def sample_data(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch\n",
    "\n",
    "\n",
    "def data_sampler(dataset, shuffle, distributed):\n",
    "    if distributed:\n",
    "        return data.distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
    "    if shuffle:\n",
    "        return data.RandomSampler(dataset)\n",
    "    else:\n",
    "        return data.SequentialSampler(dataset)\n",
    "\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(par2[k].data, alpha=1 - decay)\n",
    "\n",
    "\n",
    "def make_noise(batch, latent_dim, n_noise, device):\n",
    "    if n_noise == 1:\n",
    "        return torch.randn(batch, latent_dim, device=device)\n",
    "    noises = torch.randn(n_noise, batch, latent_dim, device=device).unbind(0)\n",
    "    return noises\n",
    "\n",
    "\n",
    "def mixing_noise(batch, latent_dim, prob, device):\n",
    "    if prob > 0 and random.random() < prob:\n",
    "        return make_noise(batch, latent_dim, 2, device)\n",
    "    else:\n",
    "        return [make_noise(batch, latent_dim, 1, device)]\n",
    "\n",
    "\n",
    "def d_logistic_loss(real_pred, fake_pred):\n",
    "    real_loss = F.softplus(-real_pred)\n",
    "    fake_loss = F.softplus(fake_pred)\n",
    "\n",
    "    return real_loss.mean() + fake_loss.mean()\n",
    "\n",
    "\n",
    "def g_nonsaturating_loss(fake_pred):\n",
    "    loss = F.softplus(-fake_pred).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def d_r1_loss(real_pred, real_img):\n",
    "    with conv2d_gradfix.no_weight_gradients():\n",
    "        grad_real, = autograd.grad(\n",
    "            outputs=real_pred.sum(), inputs=real_img, create_graph=True\n",
    "        )\n",
    "    grad_penalty = grad_real.pow(2).reshape(grad_real.shape[0], -1).sum(1).mean()\n",
    "\n",
    "    return grad_penalty\n",
    "\n",
    "\n",
    "def g_path_regularize(fake_img, latents, mean_path_length, decay=0.01):\n",
    "    noise = torch.randn_like(fake_img) / math.sqrt(\n",
    "        fake_img.shape[2] * fake_img.shape[3]\n",
    "    )\n",
    "    grad, = autograd.grad(\n",
    "        outputs=(fake_img * noise).sum(), inputs=latents, create_graph=True\n",
    "    )\n",
    "    path_lengths = torch.sqrt(grad.pow(2).sum(2).mean(1))\n",
    "    path_mean = mean_path_length + decay * (path_lengths.mean() - mean_path_length)\n",
    "    path_penalty = (path_lengths - path_mean).pow(2).mean()\n",
    "\n",
    "    return path_penalty, path_mean.detach(), path_lengths\n",
    "\n",
    "\n",
    "def train(args, loader, generator, discriminator, g_optim, d_optim, g_ema, device):\n",
    "    loader = sample_data(loader)\n",
    "\n",
    "    pbar = range(args.iter)\n",
    "\n",
    "    if get_rank() == 0:\n",
    "        pbar = tqdm(pbar, initial=args.start_iter, dynamic_ncols=True, smoothing=0.01)\n",
    "\n",
    "    mean_path_length = 0\n",
    "\n",
    "    d_loss_val = 0\n",
    "    r1_loss = torch.tensor(0.0, device=device)\n",
    "    g_loss_val = 0\n",
    "    path_loss = torch.tensor(0.0, device=device)\n",
    "    path_lengths = torch.tensor(0.0, device=device)\n",
    "    mean_path_length_avg = 0\n",
    "    loss_dict = {}\n",
    "\n",
    "    if args.distributed:\n",
    "        g_module = generator.module\n",
    "        d_module = discriminator.module\n",
    "\n",
    "    else:\n",
    "        g_module = generator\n",
    "        d_module = discriminator\n",
    "\n",
    "    accum = 0.5 ** (32 / (10 * 1000))\n",
    "    ada_aug_p = args.augment_p if args.augment_p > 0 else 0.0\n",
    "    r_t_stat = 0\n",
    "\n",
    "    if args.augment and args.augment_p == 0:\n",
    "        ada_augment = AdaptiveAugment(args.ada_target, args.ada_length, 8, device)\n",
    "\n",
    "    sample_z = torch.randn(args.n_sample, args.latent, device=device)\n",
    "\n",
    "    for idx in pbar:\n",
    "        i = idx + args.start_iter\n",
    "\n",
    "        if i > args.iter:\n",
    "            print(\"Done!\")\n",
    "            break\n",
    "\n",
    "        real_img = next(loader)\n",
    "        real_img = real_img.to(device)\n",
    "\n",
    "        requires_grad(generator, False)\n",
    "        requires_grad(discriminator, True)\n",
    "\n",
    "        noise = mixing_noise(args.batch, args.latent, args.mixing, device)\n",
    "        fake_img, _ = generator(noise)\n",
    "\n",
    "        if args.augment:\n",
    "            real_img_aug, _ = augment(real_img, ada_aug_p)\n",
    "            fake_img, _ = augment(fake_img, ada_aug_p)\n",
    "        else:\n",
    "            real_img_aug = real_img\n",
    "\n",
    "        fake_pred = discriminator(fake_img)\n",
    "        real_pred = discriminator(real_img_aug)\n",
    "        d_loss = d_logistic_loss(real_pred, fake_pred)\n",
    "\n",
    "        loss_dict[\"d\"] = d_loss\n",
    "        loss_dict[\"real_score\"] = real_pred.mean()\n",
    "        loss_dict[\"fake_score\"] = fake_pred.mean()\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optim.step()\n",
    "\n",
    "        if args.augment and args.augment_p == 0:\n",
    "            ada_aug_p = ada_augment.tune(real_pred)\n",
    "            r_t_stat = ada_augment.r_t_stat\n",
    "\n",
    "        d_regularize = i % args.d_reg_every == 0\n",
    "\n",
    "        if d_regularize:\n",
    "            real_img.requires_grad = True\n",
    "\n",
    "            if args.augment:\n",
    "                real_img_aug, _ = augment(real_img, ada_aug_p)\n",
    "            else:\n",
    "                real_img_aug = real_img\n",
    "\n",
    "            real_pred = discriminator(real_img_aug)\n",
    "            r1_loss = d_r1_loss(real_pred, real_img)\n",
    "\n",
    "            discriminator.zero_grad()\n",
    "            (args.r1 / 2 * r1_loss * args.d_reg_every + 0 * real_pred[0]).backward()\n",
    "\n",
    "            d_optim.step()\n",
    "\n",
    "        loss_dict[\"r1\"] = r1_loss\n",
    "\n",
    "        requires_grad(generator, True)\n",
    "        requires_grad(discriminator, False)\n",
    "\n",
    "        noise = mixing_noise(args.batch, args.latent, args.mixing, device)\n",
    "        fake_img, _ = generator(noise)\n",
    "\n",
    "        if args.augment:\n",
    "            fake_img, _ = augment(fake_img, ada_aug_p)\n",
    "\n",
    "        fake_pred = discriminator(fake_img)\n",
    "        g_loss = g_nonsaturating_loss(fake_pred)\n",
    "\n",
    "        loss_dict[\"g\"] = g_loss\n",
    "\n",
    "        generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optim.step()\n",
    "\n",
    "        g_regularize = i % args.g_reg_every == 0\n",
    "\n",
    "        if g_regularize:\n",
    "            path_batch_size = max(1, args.batch // args.path_batch_shrink)\n",
    "            noise = mixing_noise(path_batch_size, args.latent, args.mixing, device)\n",
    "            fake_img, latents = generator(noise, return_latents=True)\n",
    "\n",
    "            path_loss, mean_path_length, path_lengths = g_path_regularize(\n",
    "                fake_img, latents, mean_path_length\n",
    "            )\n",
    "\n",
    "            generator.zero_grad()\n",
    "            weighted_path_loss = args.path_regularize * args.g_reg_every * path_loss\n",
    "\n",
    "            if args.path_batch_shrink:\n",
    "                weighted_path_loss += 0 * fake_img[0, 0, 0, 0]\n",
    "\n",
    "            weighted_path_loss.backward()\n",
    "\n",
    "            g_optim.step()\n",
    "\n",
    "            mean_path_length_avg = (\n",
    "                    reduce_sum(mean_path_length).item() / get_world_size()\n",
    "            )\n",
    "\n",
    "        loss_dict[\"path\"] = path_loss\n",
    "        loss_dict[\"path_length\"] = path_lengths.mean()\n",
    "\n",
    "        accumulate(g_ema, g_module, accum)\n",
    "\n",
    "        loss_reduced = reduce_loss_dict(loss_dict)\n",
    "\n",
    "        d_loss_val = loss_reduced[\"d\"].mean().item()\n",
    "        g_loss_val = loss_reduced[\"g\"].mean().item()\n",
    "        r1_val = loss_reduced[\"r1\"].mean().item()\n",
    "        path_loss_val = loss_reduced[\"path\"].mean().item()\n",
    "        real_score_val = loss_reduced[\"real_score\"].mean().item()\n",
    "        fake_score_val = loss_reduced[\"fake_score\"].mean().item()\n",
    "        path_length_val = loss_reduced[\"path_length\"].mean().item()\n",
    "\n",
    "        if get_rank() == 0:\n",
    "            pbar.set_description(\n",
    "                (\n",
    "                    f\"d: {d_loss_val:.4f}; g: {g_loss_val:.4f}; r1: {r1_val:.4f}; \"\n",
    "                    f\"path: {path_loss_val:.4f}; mean path: {mean_path_length_avg:.4f}; \"\n",
    "                    f\"augment: {ada_aug_p:.4f}\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if wandb and args.wandb:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"Generator\": g_loss_val,\n",
    "                        \"Discriminator\": d_loss_val,\n",
    "                        \"Augment\": ada_aug_p,\n",
    "                        \"Rt\": r_t_stat,\n",
    "                        \"R1\": r1_val,\n",
    "                        \"Path Length Regularization\": path_loss_val,\n",
    "                        \"Mean Path Length\": mean_path_length,\n",
    "                        \"Real Score\": real_score_val,\n",
    "                        \"Fake Score\": fake_score_val,\n",
    "                        \"Path Length\": path_length_val,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                with torch.no_grad():\n",
    "                    g_ema.eval()\n",
    "                    sample, _ = g_ema([sample_z])\n",
    "                    utils.save_image(\n",
    "                        sample,\n",
    "                        f\"sample/{str(i).zfill(6)}.png\",\n",
    "                        nrow=int(args.n_sample ** 0.5),\n",
    "                        normalize=True,\n",
    "                        range=(-1, 1),\n",
    "                    )\n",
    "\n",
    "            if i % 10000 == 0:\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"g\": g_module.state_dict(),\n",
    "                        \"d\": d_module.state_dict(),\n",
    "                        \"g_ema\": g_ema.state_dict(),\n",
    "                        \"g_optim\": g_optim.state_dict(),\n",
    "                        \"d_optim\": d_optim.state_dict(),\n",
    "                        \"args\": args,\n",
    "                        \"ada_aug_p\": ada_aug_p,\n",
    "                    },\n",
    "                    f\"checkpoint/{str(i).zfill(6)}.pt\",\n",
    "                )\n",
    "\n",
    "\n",
    "class Dummy(object):\n",
    "    pass\n",
    "\n",
    "\n",
    "##### if __name__ == \"__main__\":\n",
    "args = Dummy()\n",
    "\n",
    "device = \"cuda\"\n",
    "args.iter = 800000  # \"total training iterations\"\n",
    "args.batch = 16  # \"batch sizes for each gpus\"\n",
    "args.n_sample = 64  # \"number of the samples generated during training\"\n",
    "args.size = 256  # \"image sizes for the model\"\n",
    "args.r1 = 10.  # \"weight of the r1 regularization\"\n",
    "args.path_regularize = 2  # \"weight of the path length regularization\"\n",
    "args.path_batch_shrink = 2  # batch size reducing factor for the path length regularization (reduce memory consumption)\n",
    "args.d_reg_every = 16  # interval of the applying r1 regularization\n",
    "args.g_reg_every = 4  # interval of the applying path length regularization\n",
    "args.mixing = 0.9  # probability of latent code mixing\n",
    "args.ckpt = None  # \"path to the checkpoints to resume training\"\n",
    "args.lr = 0.002  # learning rate\n",
    "args.channel_multiplier = 2  # channel multiplier factor for the model. config-f = 2, else = 1\n",
    "args.wandb = True  # use weights and biases logging\n",
    "args.local_rank = 0  # local rank for distributed training\n",
    "args.augment = True  # apply non leaking augmentation\n",
    "args.augment_p = 0.  # \"probability of applying augmentation. 0 = use adaptive augmentation\"\n",
    "args.ada_target = 0.6  # target augmentation probability for adaptive augmentation\n",
    "args.ada_length = 500 * 1000  # target duration to reach augmentation probability for adaptive augmentation\n",
    "args.ada_every = 256  # \"probability update interval of the adaptive augmentation\"\n",
    "args.latent = 512\n",
    "args.n_mlp = 8\n",
    "args.start_iter = 0\n",
    "\n",
    "n_gpu = 4\n",
    "args.distributed = n_gpu > 1\n",
    "\n",
    "torch.cuda.set_device(args.local_rank)\n",
    "#if args.distributed:\n",
    "#    torch.cuda.set_device(args.local_rank)\n",
    "#    torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\", rank=0, world_size=n_gpu)\n",
    "#    synchronize()\n",
    "\n",
    "generator = swagan.Generator(\n",
    "    args.size, args.latent, args.n_mlp, channel_multiplier=args.channel_multiplier\n",
    ").to(device)\n",
    "discriminator = swagan.Discriminator(\n",
    "    args.size, channel_multiplier=args.channel_multiplier\n",
    ").to(device)\n",
    "g_ema = swagan.Generator(\n",
    "    args.size, args.latent, args.n_mlp, channel_multiplier=args.channel_multiplier\n",
    ").to(device)\n",
    "g_ema.eval()\n",
    "accumulate(g_ema, generator, 0)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "g_reg_ratio = args.g_reg_every / (args.g_reg_every + 1)\n",
    "d_reg_ratio = args.d_reg_every / (args.d_reg_every + 1)\n",
    "\n",
    "g_optim = optim.Adam(\n",
    "    generator.parameters(),\n",
    "    lr=args.lr * g_reg_ratio,\n",
    "    betas=(0 ** g_reg_ratio, 0.99 ** g_reg_ratio),\n",
    ")\n",
    "d_optim = optim.Adam(\n",
    "    discriminator.parameters(),\n",
    "    lr=args.lr * d_reg_ratio,\n",
    "    betas=(0 ** d_reg_ratio, 0.99 ** d_reg_ratio),\n",
    ")\n",
    "\n",
    "if args.ckpt is not None:\n",
    "    print(\"load model:\", args.ckpt)\n",
    "\n",
    "    ckpt = torch.load(args.ckpt, map_location=lambda storage, loc: storage)\n",
    "\n",
    "    try:\n",
    "        ckpt_name = os.path.basename(args.ckpt)\n",
    "        args.start_iter = int(os.path.splitext(ckpt_name)[0])\n",
    "\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    generator.load_state_dict(ckpt[\"g\"])\n",
    "    discriminator.load_state_dict(ckpt[\"d\"])\n",
    "    g_ema.load_state_dict(ckpt[\"g_ema\"])\n",
    "\n",
    "    g_optim.load_state_dict(ckpt[\"g_optim\"])\n",
    "    d_optim.load_state_dict(ckpt[\"d_optim\"])\n",
    "\n",
    "    if args.distributed:\n",
    "        generator = nn.parallel.DistributedDataParallel(\n",
    "            generator,\n",
    "            device_ids=[args.local_rank],\n",
    "            output_device=args.local_rank,\n",
    "            broadcast_buffers=False,\n",
    "        )\n",
    "\n",
    "        discriminator = nn.parallel.DistributedDataParallel(\n",
    "            discriminator,\n",
    "            device_ids=[args.local_rank],\n",
    "            output_device=args.local_rank,\n",
    "            broadcast_buffers=False,\n",
    "        )\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = None\n",
    "loader = data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=args.batch,\n",
    "    sampler=data_sampler(dataset, shuffle=True, distributed=False),\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "if get_rank() == 0 and wandb is not None and args.wandb:\n",
    "    wandb.init(project=\"camelxstyle\")\n",
    "\n",
    "#train(args, loader, generator, discriminator, g_optim, d_optim, g_ema, device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afdd0c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (style): Sequential(\n",
       "    (0): PixelNorm()\n",
       "    (1): EqualLinear(512, 512)\n",
       "    (2): EqualLinear(512, 512)\n",
       "    (3): EqualLinear(512, 512)\n",
       "    (4): EqualLinear(512, 512)\n",
       "    (5): EqualLinear(512, 512)\n",
       "    (6): EqualLinear(512, 512)\n",
       "    (7): EqualLinear(512, 512)\n",
       "    (8): EqualLinear(512, 512)\n",
       "  )\n",
       "  (input): ConstantInput()\n",
       "  (conv1): StyledConv(\n",
       "    (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
       "    (noise): NoiseInjection()\n",
       "    (activate): FusedLeakyReLU()\n",
       "  )\n",
       "  (to_field1): ToFields(\n",
       "    (conv): ModulatedConv2d(512, 12, 1, upsample=False, downsample=False)\n",
       "  )\n",
       "  (convs): ModuleList(\n",
       "    (0): StyledConv(\n",
       "      (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "    (1): StyledConv(\n",
       "      (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "    (2): StyledConv(\n",
       "      (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "    (3): StyledConv(\n",
       "      (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "    (4): StyledConv(\n",
       "      (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "    (5): StyledConv(\n",
       "      (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "    (6): StyledConv(\n",
       "      (conv): ModulatedConv2d(512, 512, 3, upsample=True, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "    (7): StyledConv(\n",
       "      (conv): ModulatedConv2d(512, 512, 3, upsample=False, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "    (8): StyledConv(\n",
       "      (conv): ModulatedConv2d(512, 256, 3, upsample=True, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "    (9): StyledConv(\n",
       "      (conv): ModulatedConv2d(256, 256, 3, upsample=False, downsample=False)\n",
       "      (noise): NoiseInjection()\n",
       "      (activate): FusedLeakyReLU()\n",
       "    )\n",
       "  )\n",
       "  (upsamples): ModuleList()\n",
       "  (to_fields): ModuleList(\n",
       "    (0): ToFields(\n",
       "      (iwt): InverseHaarTransform()\n",
       "      (upsample): Upsample()\n",
       "      (dwt): HaarTransform()\n",
       "      (conv): ModulatedConv2d(512, 12, 1, upsample=False, downsample=False)\n",
       "    )\n",
       "    (1): ToFields(\n",
       "      (iwt): InverseHaarTransform()\n",
       "      (upsample): Upsample()\n",
       "      (dwt): HaarTransform()\n",
       "      (conv): ModulatedConv2d(512, 12, 1, upsample=False, downsample=False)\n",
       "    )\n",
       "    (2): ToFields(\n",
       "      (iwt): InverseHaarTransform()\n",
       "      (upsample): Upsample()\n",
       "      (dwt): HaarTransform()\n",
       "      (conv): ModulatedConv2d(512, 12, 1, upsample=False, downsample=False)\n",
       "    )\n",
       "    (3): ToFields(\n",
       "      (iwt): InverseHaarTransform()\n",
       "      (upsample): Upsample()\n",
       "      (dwt): HaarTransform()\n",
       "      (conv): ModulatedConv2d(512, 12, 1, upsample=False, downsample=False)\n",
       "    )\n",
       "    (4): ToFields(\n",
       "      (iwt): InverseHaarTransform()\n",
       "      (upsample): Upsample()\n",
       "      (dwt): HaarTransform()\n",
       "      (conv): ModulatedConv2d(256, 12, 1, upsample=False, downsample=False)\n",
       "    )\n",
       "  )\n",
       "  (noises): Module()\n",
       "  (iwt): InverseHaarTransform()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ea3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
